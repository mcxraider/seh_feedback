{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from groq import Groq\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "from tqdm import trange\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import logging\n",
    "from math import ceil\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "## load env variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.environ[\"GROQ_API_KEY\"]\n",
    "CHAT_MODEL   = os.environ[\"CHAT_MODEL\"]\n",
    "client       = Groq()\n",
    "\n",
    "REGION = 'VN'\n",
    "CSV_OUTPUT_LOCATION = f'../data/labelled_feedback/{REGION}_labelled_feedback_data_with_URL.csv'\n",
    "\n",
    "#  load prompt from yaml file\n",
    "GENERATE_EN_LABELS_PROMPT = '''\n",
    "You are a linguistics professor with extensive experience in text analysis and classification. \n",
    "Your task is to first translate and then categorise seller feedback for an article webpage on an e-commerce education platform.\n",
    "\n",
    "Follow these steps carefully:\n",
    "1. **Understand the Task**: Each feedback item must be assigned one or more labels from the following list:\n",
    "   - 'Negative Complaint'\n",
    "   - 'Constructive Criticism'\n",
    "   - 'Design Feedback'\n",
    "   - 'Positive Comment'\n",
    "   - 'Neutral'\n",
    "   - 'Unknown'\n",
    "\n",
    "2. **Interpretation Guidelines**:\n",
    "    - Negative Complaint Expresses dissatisfaction without offering suggestions for improvement. (E.g., \"The UI is terrible and frustrating to use.\")\n",
    "    - Constructive Criticism – Offers specific feedback on what could be improved. (E.g., \"The UI could be more intuitive by reducing unnecessary steps.\")\n",
    "    - Design Feedback – Mentions aspects related to visual design, user experience, or layout. (E.g., \"The font is too small and hard to read.\")\n",
    "    - Positive Comment – Expresses satisfaction or praise. (E.g., \"Great platform! I love using it.\")\n",
    "    - Neutral – Does not express strong positive or negative sentiment. (E.g., \"This feature exists.\")\n",
    "    - Unknown – The intent or meaning of the feedback is unclear. (E.g., \"hmmm... idk.\")\n",
    "\n",
    "You are not to write any code, but just use your knowledge to classify the feedback.\n",
    "Your output should be the feedback IDs and their corresponding label.\n",
    "\n",
    "Example Output format:\n",
    "[{{\"feedback_id\": 123456, \"label\": [\"Negative Complaint\"]}}, {{\"feedback_id\": 423456, \"label\": [\"Constructive Criticism\",\"Design Feedback\"]}}, {{\"feedback_id\": 654321, \"label\": [\"Negative Complaint\"]}}]\n",
    "\n",
    "Now classify the following feedback:\n",
    "Feedbacks: {pairs}\n",
    "\n",
    "Double check and ensure that your format output matches the example output format provided.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_region_data(region: str) -> pd.DataFrame:\n",
    "    # Define the file path based on the region\n",
    "    region_path = f\"../content/drive/My Drive/seh_data/feedback_{region}.xlsx\"\n",
    "\n",
    "    # Specify columns to read\n",
    "    columns_to_read = [\"Feedback id\", \"Feedback 1\", \"Feedback 2\", \"URL\"]\n",
    "\n",
    "    # Load the data into a DataFrame\n",
    "    df = pd.read_excel(region_path, usecols=columns_to_read)\n",
    "\n",
    "    # Filter out rows with missing or invalid data\n",
    "    df_filtered = df[\n",
    "        (df['Feedback 1'].notna()) &\n",
    "        (df['Feedback 2'].notna()) &\n",
    "        (df['Feedback 2'] != '{\"description\":\"\"}')\n",
    "    ].copy()  # Ensure df_filtered is a separate copy\n",
    "\n",
    "    # Extract the 'description' field from JSON in 'Feedback 2'\n",
    "    df_filtered.loc[:, 'Feedback 2'] = df_filtered['Feedback 2'].apply(\n",
    "        lambda x: json.loads(x)['description'] if isinstance(x, str) else None\n",
    "    )\n",
    "\n",
    "    # Convert 'Feedback id' to numeric and drop rows with invalid IDs\n",
    "    df_filtered.loc[:, 'Feedback id'] = pd.to_numeric(df_filtered['Feedback id'], errors='coerce')\n",
    "    df_filtered = df_filtered.dropna(subset=['Feedback id'])\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "\n",
    "def format_llm_input(df: pd.DataFrame) -> Tuple[List[Dict[str, str]], Dict[int, str]]:\n",
    "    # Extract feedback IDs and feedback text\n",
    "    feedback_ids = list(df['Feedback id'])\n",
    "    feedback_texts = list(df['Feedback 2'])\n",
    "    feedback_urls = list(df['URL'])\n",
    "\n",
    "    # Create a dictionary mapping feedback IDs to feedback text\n",
    "    id_feedback = {int(feedback_id): [feedback,\n",
    "                                      feedback_url]\n",
    "                   for feedback_id, feedback, feedback_url in zip(feedback_ids, feedback_texts, feedback_urls)}\n",
    "\n",
    "    # Prepare the LLM input as a list of dictionaries\n",
    "    llm_input = [{'id': feedback_id,\n",
    "                  'feedback': feedback_ls[0]} for feedback_id, feedback_ls in id_feedback.items()]\n",
    "\n",
    "    return llm_input, id_feedback\n",
    "\n",
    "\n",
    "def get_id_labels(llm_response: str, pattern: str = r'\\[\\s*\\{(?:.|\\n)*\\}\\s*\\]') -> List[Dict[str, str]]:\n",
    "    if not isinstance(llm_response, str):\n",
    "        raise TypeError(\"The LLM response must be a string.\")\n",
    "\n",
    "    try:\n",
    "        # Find the match\n",
    "        match = re.search(pattern, llm_response, re.DOTALL)\n",
    "        if not match:\n",
    "            print(f\"THIS RESPONSE WAS PRODUCED AND WAS UNABLE TO BE PICKED UP:\\n{llm_response}\")\n",
    "            raise ValueError(\"No valid JSON list found in the response.\")\n",
    "\n",
    "        json_string = match.group(0)\n",
    "        result = json.loads(json_string)\n",
    "\n",
    "        # Validate the structure of the result\n",
    "        if not isinstance(result, list) or not all(isinstance(item, dict) for item in result):\n",
    "            raise ValueError(\"Extracted JSON is not a list of dictionaries.\")\n",
    "\n",
    "        return result\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"Failed to decode JSON: {e}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "def generate_batch_labels(id_feedback_pairs, label_prompt: str, client):\n",
    "    prompt = PromptTemplate(\n",
    "        template=label_prompt,\n",
    "        input_variables=[\"pairs\"],\n",
    "    )\n",
    "\n",
    "    final_prompt = prompt.format(pairs=id_feedback_pairs)\n",
    "\n",
    "    # Generate the completion by interacting with the language model API\n",
    "    completion = client.chat.completions.create(\n",
    "        model=CHAT_MODEL,\n",
    "        messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": final_prompt\n",
    "                    }\n",
    "                    ],\n",
    "        temperature=0,  # Control the randomness of the output (lower means less random)\n",
    "        max_tokens=1024,  # Limit the response length\n",
    "        top_p=1  # Nucleus sampling parameter (1 means only the most likely tokens are considered)\n",
    "    )\n",
    "\n",
    "    # Initialize an empty string to accumulate the response content\n",
    "    response = completion.choices[0].message.content\n",
    "\n",
    "    tokens_used = completion.usage.total_tokens\n",
    "    pairings = get_id_labels(response)\n",
    "\n",
    "    return pairings, tokens_used\n",
    "\n",
    "\n",
    "def generate_labels(prompt, llm_input, num_per_batch):\n",
    "    if not isinstance(llm_input, list):\n",
    "        raise TypeError(\"llm_input must be a list\")\n",
    "\n",
    "    num_batches = ceil(len(llm_input) / num_per_batch)\n",
    "    start_index = 0\n",
    "    just_in_case_stop_index = 0\n",
    "    total_tokens = 0\n",
    "    labelled_data = []\n",
    "\n",
    "    try:\n",
    "        for i in trange(num_batches):\n",
    "            end_index = min(start_index + num_per_batch, len(llm_input))\n",
    "            batch_pairs = llm_input[start_index:end_index]\n",
    "\n",
    "            try:\n",
    "                batch_labels, tokens_used = generate_batch_labels(batch_pairs, prompt, client)\n",
    "                total_tokens += tokens_used\n",
    "            except ValueError:\n",
    "                intermediate_end = min(start_index + 5, len(llm_input))\n",
    "                batch_pairs = llm_input[start_index:intermediate_end]\n",
    "\n",
    "                batch_labels, tokens_used = generate_batch_labels(batch_pairs, prompt, client)\n",
    "                total_tokens += tokens_used\n",
    "\n",
    "                intermediate_start = intermediate_end\n",
    "                if intermediate_end < end_index:\n",
    "                    batch_pairs = llm_input[intermediate_start:end_index]\n",
    "                    batch_labels, tokens_used = generate_batch_labels(batch_pairs, prompt, client)\n",
    "                    total_tokens += tokens_used\n",
    "\n",
    "\n",
    "                if (i + 1) % 5 == 0:\n",
    "                    print(f\"\\nCompleted {i + 1} iterations. To prevent rate limits, sleeping for 60 seconds...\\n\")\n",
    "                    time.sleep(60)\n",
    "\n",
    "                start_index = intermediate_end\n",
    "                just_in_case_stop_index = intermediate_end\n",
    "                continue  # Skip the rest of the loop\n",
    "\n",
    "            labelled_data.extend(batch_labels)\n",
    "            start_index = end_index\n",
    "\n",
    "            if (i + 1) % 5 == 0:\n",
    "                print(f\"\\nCompleted {i + 1} iterations. To prevent rate limits, sleeping for 60 seconds...\\n\")\n",
    "                time.sleep(60)\n",
    "\n",
    "            just_in_case_stop_index = end_index\n",
    "            time.sleep(2)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing: {e}\")\n",
    "        print(f\"Stopped at batch {just_in_case_stop_index}\\n\")\n",
    "        sys.exit()\n",
    "\n",
    "    print(\"\\nAll comments have been translated!\\n\")\n",
    "\n",
    "    return total_tokens, labelled_data\n",
    "\n",
    "\n",
    "def pair_id_feedback(id_feedback, feedback_labels: list, translated_llm_input):\n",
    "    for i in range(len(feedback_labels)):\n",
    "        # get the feedback id\n",
    "        id = feedback_labels[i]['feedback_id']\n",
    "        feedback_labels[i]['Translated Comment'] = translated_llm_input[i]['feedback']\n",
    "        # add original comment\n",
    "        # feedback_labels[i]['Original Comment'] = trans\n",
    "        feedback_labels[i]['URL'] = id_feedback[id][1]\n",
    "\n",
    "    return feedback_labels\n",
    "\n",
    "\n",
    "def process_output(combined, pattern=r\"/([^/]+)/(\\d+)\"):\n",
    "    # Convert to a DataFrame\n",
    "    combined_df = pd.DataFrame(combined)\n",
    "\n",
    "    # Rename columns to match the required format\n",
    "    combined_df.rename(columns={'feedback_id': 'Feedback id',\n",
    "                                'label': 'Label(s)',\n",
    "                                'URL': 'Link to Article'},\n",
    "                       inplace=True)\n",
    "\n",
    "    # Function to extract text type and article number dynamically\n",
    "    def extract_text_and_number(url):\n",
    "        match = re.search(pattern, url)\n",
    "        if match:\n",
    "            return match.group(1), match.group(2)\n",
    "        return \"NIL\", \"NIL\"  # Default if no match\n",
    "\n",
    "    # Apply extraction to the \"Link to Article\" column\n",
    "    combined_df[['Type', 'Article ID']] = combined_df['Link to Article'].apply(\n",
    "        lambda url: pd.Series(extract_text_and_number(url))\n",
    "    )\n",
    "\n",
    "    # reorder the columns\n",
    "    desired_order = ['Article ID', 'Translated Comment', 'Label(s)', 'Link to Article', 'Type']\n",
    "    combined_df = combined_df[desired_order]\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "# edit this cos ure not using os\n",
    "def export_to_csv(df, path):\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "    # Overwrite or create the file\n",
    "    df.to_csv(path, index=False, mode='w')\n",
    "\n",
    "\n",
    "def main():\n",
    "    df = load_region_data(REGION)\n",
    "    llm_input, id_feedback = format_llm_input(df)\n",
    "\n",
    "    # enter translation function\n",
    "    num_to_translate = 16\n",
    "    translated_llm_input = translate_region_text(llm_input[:num_to_translate], batch_size=3)\n",
    "\n",
    "    # Plan on what to do with this token consumed.\n",
    "    total_tokens_consumed, feedback_labels = generate_labels(GENERATE_EN_LABELS_PROMPT, translated_llm_input, num_per_batch=10)\n",
    "    combined = pair_id_feedback(id_feedback, feedback_labels)\n",
    "    final_df = process_output(combined)\n",
    "\n",
    "    export_to_csv(final_df, CSV_OUTPUT_LOCATION)\n",
    "    print(f\"\\n\\nThis operation run required {total_tokens_consumed} tokens\\n\\n\")\n",
    "    return total_tokens_consumed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_region_data(REGION)\n",
    "llm_input, id_feedback = format_llm_input(df)\n",
    "\n",
    "# enter translation function\n",
    "# num_to_translate = 50\n",
    "translated_llm_input = translate_region_text(llm_input, batch_size=3)\n",
    "\n",
    "    # Plan on what to do with this token consumed.\n",
    "total_tokens_consumed, feedback_labels = generate_labels(GENERATE_EN_LABELS_PROMPT, translated_llm_input, num_per_batch=10)\n",
    "combined = pair_id_feedback(id_feedback, feedback_labels, translated_llm_input)\n",
    "final_df = process_output(combined)\n",
    "\n",
    "export_to_csv(final_df, CSV_OUTPUT_LOCATION)\n",
    "print(f\"\\n\\nThis operation run required {total_tokens_consumed} tokens\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

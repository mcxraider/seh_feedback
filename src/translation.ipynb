{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import trange\n",
    "import requests\n",
    "import json\n",
    "from typing import List, Dict, Tuple, Any\n",
    "import time\n",
    "\n",
    "\n",
    "## load env variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "HF_KEY = os.environ['HUGGINGFACE']\n",
    "API_URL = os.environ['HF_API_URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create global var - Num of HF inference calls\n",
    "\n",
    "def load_region_data(region: str) -> pd.DataFrame:\n",
    "    # Define the file path based on the region\n",
    "    region_path = f\"../data/official_data/feedback_{region}.xlsx\"\n",
    "\n",
    "    # Specify columns to read\n",
    "    columns_to_read = [\"Feedback id\", \"Feedback 1\", \"Feedback 2\", \"URL\"]\n",
    "\n",
    "    # Load the data into a DataFrame\n",
    "    df = pd.read_excel(region_path, usecols=columns_to_read)\n",
    "\n",
    "    # Filter out rows with missing or invalid data\n",
    "    df_filtered = df[\n",
    "        (df['Feedback 1'].notna()) &\n",
    "        (df['Feedback 2'].notna()) &\n",
    "        (df['Feedback 2'] != '{\"description\":\"\"}')\n",
    "    ].copy()  # Ensure df_filtered is a separate copy\n",
    "\n",
    "    # Extract the 'description' field from JSON in 'Feedback 2'\n",
    "    df_filtered.loc[:, 'Feedback 2'] = df_filtered['Feedback 2'].apply(\n",
    "        lambda x: json.loads(x)['description'] if isinstance(x, str) else None\n",
    "    )\n",
    "\n",
    "    # Convert 'Feedback id' to numeric and drop rows with invalid IDs\n",
    "    df_filtered.loc[:, 'Feedback id'] = pd.to_numeric(df_filtered['Feedback id'], errors='coerce')\n",
    "    df_filtered = df_filtered.dropna(subset=['Feedback id'])\n",
    "    df_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "def translate_batch(region_lowercased: str, foreign_texts: list):\n",
    "    payload = {\n",
    "        \"inputs\": [text for text in foreign_texts],\n",
    "        \"parameters\": {\"src_lang\": region_lowercased,\n",
    "                        \"tgt_lang\": \"en\"}\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        API_URL, headers={\"Authorization\": f\"Bearer {HF_KEY}\"}, json=payload\n",
    "    )    \n",
    "    output = response.json()\n",
    "\n",
    "    if 'error' in output:\n",
    "        raise Exception(output['error'])\n",
    "    \n",
    "    translated_text = [{\"Original\": foreign_texts[i],\n",
    "                        \"Translated\" : output[i]['translation_text'][3:]} for i in range(len(output))]\n",
    "    \n",
    "    return translated_text\n",
    "\n",
    "\n",
    "def format_llm_input(df: pd.DataFrame) -> Tuple[List[Dict[str, str]], Dict[int, str]]:\n",
    "    # Extract feedback IDs and feedback text\n",
    "    feedback_ids = list(df['Feedback id'])\n",
    "    feedback_texts = list(df['Feedback 2'])\n",
    "\n",
    "    # Create a dictionary mapping feedback IDs to feedback text\n",
    "    id_feedback = {int(feedback_id): feedback for feedback_id, feedback in zip(feedback_ids, feedback_texts)}\n",
    "\n",
    "    # Prepare the LLM input as a list of dictionaries\n",
    "    llm_input = [{'id': feedback_id, 'feedback': feedback} for feedback_id, feedback in id_feedback.items()]\n",
    "\n",
    "    return llm_input, id_feedback\n",
    "\n",
    "\n",
    "# Loop through the llm_input\n",
    "def translate_region_text(llm_input, region_lowercased):\n",
    "    print(\"\\nTranslation in progress now...\\n\")\n",
    "    \n",
    "    collected_translations = []\n",
    "    \n",
    "    for i in trange(0,len(llm_input)-2,2):\n",
    "        # slice the input \n",
    "        batch_list_of_dicts = llm_input[i:i+2]\n",
    "        batch_list = [dic['feedback'] for dic in batch_list_of_dicts]\n",
    "        res = translate_batch(region_lowercased, batch_list)\n",
    "        collected_translations.extend(res)\n",
    "        time.sleep(1)\n",
    "        if i >=5:\n",
    "            break\n",
    "    return collected_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SP14267\\Desktop\\seh\\venv\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Translation in progress now...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 3/215 [00:58<1:09:09, 19.57s/it]\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Model facebook/mbart-large-50-many-to-many-mmt is currently loading",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m load_region_data(region)\n\u001b[0;32m      4\u001b[0m llm_input, id_feedback \u001b[38;5;241m=\u001b[39m format_llm_input(df)\n\u001b[1;32m----> 5\u001b[0m translations \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate_region_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregion_lowercased\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 76\u001b[0m, in \u001b[0;36mtranslate_region_text\u001b[1;34m(llm_input, region_lowercased)\u001b[0m\n\u001b[0;32m     74\u001b[0m batch_list_of_dicts \u001b[38;5;241m=\u001b[39m llm_input[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     75\u001b[0m batch_list \u001b[38;5;241m=\u001b[39m [dic[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeedback\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m dic \u001b[38;5;129;01min\u001b[39;00m batch_list_of_dicts]\n\u001b[1;32m---> 76\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregion_lowercased\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m collected_translations\u001b[38;5;241m.\u001b[39mextend(res)\n\u001b[0;32m     78\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 45\u001b[0m, in \u001b[0;36mtranslate_batch\u001b[1;34m(region_lowercased, foreign_texts)\u001b[0m\n\u001b[0;32m     42\u001b[0m output \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output:\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     47\u001b[0m translated_text \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal\u001b[39m\u001b[38;5;124m\"\u001b[39m: foreign_texts[i],\n\u001b[0;32m     48\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslated\u001b[39m\u001b[38;5;124m\"\u001b[39m : output[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranslation_text\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m3\u001b[39m:]} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(output))]\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m translated_text\n",
      "\u001b[1;31mException\u001b[0m: Model facebook/mbart-large-50-many-to-many-mmt is currently loading"
     ]
    }
   ],
   "source": [
    "region  = \"VN_Article\"\n",
    "region_lowercased = \"vn\"\n",
    "df = load_region_data(region)\n",
    "llm_input, id_feedback = format_llm_input(df)\n",
    "translations = translate_region_text(llm_input, region_lowercased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

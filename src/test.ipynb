{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from groq import Groq\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import logging\n",
    "from math import ceil\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "## load evv variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.environ[\"GROQ_API_KEY\"]\n",
    "CHAT_MODEL = os.environ[\"CHAT_MODEL\"]\n",
    "client = Groq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_region_data(region):\n",
    "    region_path = f\"../data/official_data/feedback_{region}.xls\"\n",
    "\n",
    "    columns_to_read = [\"Feedback id\", \"Feedback 1\", \"Feedback 2\"]\n",
    "    df = pd.read_excel(region_path, usecols=columns_to_read)\n",
    "\n",
    "    df_filtered = df[\n",
    "        (df['Feedback 1'].notna()) &\n",
    "        (df['Feedback 2'].notna()) &\n",
    "        (df['Feedback 2'] != '{\"description\":\"\"}')\n",
    "    ]\n",
    "\n",
    "    df_filtered['Feedback 2'] = df_filtered['Feedback 2'].apply(lambda x: json.loads(x)['description'])\n",
    "\n",
    "    # Handle problematic 'Feedback id' values\n",
    "    df_filtered['Feedback id'] = pd.to_numeric(df_filtered['Feedback id'], errors='coerce')\n",
    "    df_filtered = df_filtered.dropna(subset=['Feedback id'])\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "def format_llm_input(df):\n",
    "    feedback_id = list(df['Feedback id'])\n",
    "    feedback_2 = list(df['Feedback 2'].values)\n",
    "    id_feedback = {}\n",
    "    for i in range(len(feedback_id)):\n",
    "        id_feedback[feedback_id[i]]= feedback_2[i]\n",
    "    input = []\n",
    "    for id, feedback in id_feedback.items():\n",
    "        input.append({id, feedback})\n",
    "        \n",
    "    return input, id_feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_LABELS_PROMPT = '''\n",
    "You are an linguistics professor tasked with classifying seller feedback for an e-commerce platform. \n",
    "Each feedback item should be categorised into one or more appropriate labels from the following list:\n",
    "['Negative_Complaint','Constructive_Criticism','Design_Feedback','Positive Comment','Neutral']\n",
    "You are not to write any code, but just use your knowledge to classify the feedback.\n",
    "Your output should be the feedback IDs and their corresponding label.\n",
    "\n",
    "Now classify the following feedback:\n",
    "Feedbacks: {pairs}\n",
    "\n",
    "Example Output format:\n",
    "[{{\"feedback_id\": 123456, \"label\": \"Negative_Complaint\"}}, {{\"feedback_id\": 423456,\"label\": \"Constructive_Criticism\"}}, {{\"feedback_id\": 654321,\"label\": \"Negative_Complaint\"}}]\n",
    "\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_labels(llm_response, pattern=r'\\[\\{.*?\\}\\]'):\n",
    "    if not isinstance(llm_response, str):\n",
    "        raise TypeError(\"The LLM response must be a string.\")\n",
    "\n",
    "    try:\n",
    "        # Find the match\n",
    "        match = re.search(pattern, llm_response, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(\"No valid JSON list found in the response.\")\n",
    "\n",
    "        json_string = match.group(0)\n",
    "        result = json.loads(json_string)\n",
    "\n",
    "        # Validate the structure of the result\n",
    "        if not isinstance(result, list) or not all(isinstance(item, dict) for item in result):\n",
    "            raise ValueError(\"Extracted JSON is not a list of dictionaries.\")\n",
    "\n",
    "        return result\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"Failed to decode JSON: {e}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "def generate_batch_labels(id_feedback_pairs, label_prompt, client):\n",
    "    prompt = PromptTemplate(\n",
    "        template=label_prompt,\n",
    "        input_variables=[\"pairs\"],\n",
    "    )\n",
    "\n",
    "    final_prompt = prompt.format(pairs=id_feedback_pairs)\n",
    "\n",
    "    # Generate the completion by interacting with the language model API\n",
    "    completion = client.chat.completions.create(\n",
    "        model=CHAT_MODEL,\n",
    "        messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\", \n",
    "                        \"content\": final_prompt\n",
    "                    }\n",
    "                    ],\n",
    "        temperature=0,  # Control the randomness of the output (lower means less random)\n",
    "        max_tokens=1024,  # Limit the response length\n",
    "        top_p=1,  # Nucleus sampling parameter (1 means only the most likely tokens are considered)\n",
    "        stream=True,  # Enable streaming of the response chunks\n",
    "        stop=None,  # Define stopping conditions (None means no stopping condition)\n",
    "    )\n",
    "\n",
    "    # Initialize an empty string to accumulate the response content\n",
    "    response = \"\"\"\"\"\"\n",
    "    for chunk in completion:\n",
    "        # Append each chunk of content to the response string\n",
    "        response += chunk.choices[0].delta.content or \"\"\n",
    "        \n",
    "    pairings = get_id_labels(response)\n",
    "\n",
    "    return pairings\n",
    "\n",
    "def generate_labels(llm_input, num_per_batch, output_file=f'../data/llm_responses.json'):\n",
    "    # Determine the number of batches\n",
    "    num_batches = ceil(len(llm_input) / num_per_batch)\n",
    "\n",
    "    # Initialise indices for batch processing\n",
    "    start_index = 0\n",
    "\n",
    "    # Open the JSON file in append mode\n",
    "    try:\n",
    "        for i in range(num_batches):\n",
    "            # Calculate the batch indices\n",
    "            end_index = start_index + num_per_batch\n",
    "            batch_pairs = llm_input[start_index:end_index]\n",
    "\n",
    "            # Call the function to generate labels for the current batch\n",
    "            batch_labels = generate_batch_labels(batch_pairs, GENERATE_LABELS_PROMPT, client)\n",
    "            \n",
    "            # Update the start index for the next batch\n",
    "            start_index = end_index\n",
    "\n",
    "            # Write the current batch to the JSON file\n",
    "            with open(output_file, 'a') as json_file:\n",
    "                # Convert the batch to a JSON string and write it\n",
    "                for label in batch_labels:\n",
    "                    json_file.write(json.dumps(label) + '\\n')\n",
    "            \n",
    "            if i >=2:\n",
    "                break\n",
    "\n",
    "        print(f\"All batches written to {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing: {e}\")\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads a JSON file where each line is a separate JSON object.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of all JSON objects read from the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = []\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            for line in json_file:\n",
    "                data.append(json.loads(line.strip()))\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {file_path} does not exist.\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        \n",
    "def pair_id_feedback(id_feedback, feedback_labels):\n",
    "    for i in range(len(feedback_labels)):\n",
    "        id = feedback_labels[i]['feedback_id']\n",
    "        comment = id_feedback[id]\n",
    "        feedback_labels[i]['Comment'] = comment\n",
    "        \n",
    "    return feedback_labels\n",
    "\n",
    "\n",
    "def write_to_csv(region, combined):\n",
    "    # Convert to a DataFrame\n",
    "    combined_df = pd.DataFrame(combined)\n",
    "\n",
    "    # Rename columns to match the required format\n",
    "    combined_df.rename(columns={'feedback_id': 'Feedback id',\n",
    "                       'label': 'Label',\n",
    "                       'Comment': 'Comment'},\n",
    "             inplace=True)\n",
    "\n",
    "    # Save to CSV\n",
    "    csv_filename = f'../data/{region}_labelled_feedback_data.csv'\n",
    "    combined_df.to_csv(csv_filename, index=False)\n",
    "    print(f\"{region} Labels wrote to csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SP14267\\AppData\\Local\\Temp\\ipykernel_23704\\310436252.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['Feedback 2'] = df_filtered['Feedback 2'].apply(lambda x: json.loads(x)['description'])\n",
      "C:\\Users\\SP14267\\AppData\\Local\\Temp\\ipykernel_23704\\310436252.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['Feedback id'] = pd.to_numeric(df_filtered['Feedback id'], errors='coerce')\n",
      "2025-01-27 16:08:14,724 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-27 16:08:15,637 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-27 16:08:17,038 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All batches written to ../data/llm_responses.json\n"
     ]
    }
   ],
   "source": [
    "region = \"SG\"\n",
    "df = load_region_data(region)\n",
    "llm_input, id_feedback = format_llm_input(df)\n",
    "generate_labels(llm_input, num_per_batch=5)\n",
    "feedback_labels = read_json_file(file_path=f'../data/llm_responses.json')\n",
    "combined = pair_id_feedback(id_feedback, feedback_labels)\n",
    "write_to_csv(region, combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
